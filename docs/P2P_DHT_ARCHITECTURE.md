# P2P DHT Architecture and MuSig2 Coordination

**Version**: 1.0.0  
**Date**: November 1, 2025  
**Status**: Complete Documentation

---

## Table of Contents

1. [Overview](#overview)
2. [Kademlia DHT Fundamentals](#kademlia-dht-fundamentals)
3. [libp2p DHT Implementation](#libp2p-dht-implementation)
4. [Lotus DHT Architecture](#lotus-dht-architecture)
5. [Visual DHT Structure](#visual-dht-structure)
6. [DHT State and Lifecycle](#dht-state-and-lifecycle)
7. [MuSig2 Coordination via DHT](#musig2-coordination-via-dht)
8. [Network Communication Patterns](#network-communication-patterns)
9. [Technical Implementation Details](#technical-implementation-details)
10. [Performance and Scaling](#performance-and-scaling)

---

## Overview

The **Distributed Hash Table (DHT)** in lotus-lib provides the foundational infrastructure for decentralized peer-to-peer coordination. This document explains how the DHT is constructed, what it looks like both conceptually and technically, and how individual nodes communicate to facilitate MuSig2 multi-signature coordination.

**Key Components:**

- **Kademlia DHT**: Industry-standard distributed hash table algorithm
- **libp2p kad-dht**: Production-ready implementation used by IPFS, Filecoin, Ethereum 2.0
- **Resource Announcements**: Session discovery and coordination metadata
- **Direct Messaging**: Point-to-point communication for cryptographic material exchange

**Design Goals:**

1. **Decentralized Discovery**: No central server required for session coordination
2. **Resilient**: Network continues functioning even with node failures
3. **Scalable**: Efficient routing with O(log n) lookup complexity
4. **Secure**: Cryptographic authentication and validation at all layers

---

## Kademlia DHT Fundamentals

### What is a DHT?

A **Distributed Hash Table** is a decentralized data structure that provides:

- **Key-Value Storage**: Distributed across network nodes
- **Efficient Lookups**: Logarithmic time complexity O(log n)
- **Self-Organization**: Nodes join/leave dynamically without coordination
- **Fault Tolerance**: Data replicated across multiple nodes

### Kademlia Algorithm

Kademlia is a specific DHT algorithm with these characteristics:

**1. Node IDs and XOR Distance Metric**

```
Each node has a 256-bit ID (SHA-256 hash)

Distance between two IDs:
d(A, B) = A âŠ• B (bitwise XOR)

Example:
Node A: 1010101010...
Node B: 1011001010...
Distance: 0001100000... (smaller = closer)
```

**2. Routing Table Structure**

Each node maintains a routing table organized into **k-buckets**:

```
k-bucket[i] contains nodes at distance 2^i to 2^(i+1) - 1

Routing Table (256 k-buckets):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ k-bucket[0]:  distance 2^0  to 2^1  - 1 â”‚ â† Closest nodes
â”‚ k-bucket[1]:  distance 2^1  to 2^2  - 1 â”‚
â”‚ k-bucket[2]:  distance 2^2  to 2^3  - 1 â”‚
â”‚ ...                                     â”‚
â”‚ k-bucket[255]: distance 2^255 to 2^256 â”‚ â† Furthest nodes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Each k-bucket holds up to k peers (typically k=20)
```

**3. Lookup Algorithm**

When searching for a key, nodes perform iterative lookups:

```
1. Find k closest nodes to target key from local routing table
2. Query those nodes for even closer nodes
3. Repeat until target is found or no closer nodes exist
4. Complexity: O(log n) queries across the network
```

**4. Data Storage and Retrieval**

```
PUT(key, value):
  1. Compute nodeID = SHA256(key)
  2. Find k closest nodes to nodeID
  3. Store value on those k nodes (replication)

GET(key):
  1. Compute nodeID = SHA256(key)
  2. Query k closest nodes to nodeID
  3. Return first valid value found
```

### Why Kademlia?

**Advantages for P2P Networks:**

âœ… **Efficient Routing**: O(log n) lookup complexity  
âœ… **Symmetric Distance**: XOR metric is symmetric (d(A,B) = d(B,A))  
âœ… **Flexible Topology**: Nodes can join/leave without disruption  
âœ… **Load Balancing**: Uniform distribution of keys across nodes  
âœ… **Redundancy**: Automatic replication across multiple nodes

**Used By:**

- BitTorrent (Mainline DHT)
- IPFS (InterPlanetary File System)
- Ethereum 2.0 (Peer Discovery)
- Storj (Decentralized Storage)

---

## libp2p DHT Implementation

### Architecture

lotus-lib uses `@libp2p/kad-dht`, the standard Kademlia DHT implementation for libp2p:

```typescript
import { kadDHT, KadDHT } from '@libp2p/kad-dht'

// DHT is configured as a libp2p service
const config = {
  services: {
    kadDHT: kadDHT({
      protocol: '/lotus/kad/1.0.0', // Protocol identifier
      clientMode: false, // Server mode: participate in DHT
      peerInfoMapper: passthroughMapper, // Address filtering
    }),
  },
}
```

### Operating Modes

**1. Server Mode** (`clientMode: false`)

```
âœ… Participates in DHT network
âœ… Routes queries for other peers
âœ… Stores key-value pairs from network
âœ… Responds to DHT queries
âœ… Contributes to network health

Use Case: Long-running nodes, bootstrap nodes
```

**2. Client Mode** (`clientMode: true`)

```
âœ… Queries DHT network
âŒ Does NOT route queries
âŒ Does NOT store network data
âŒ Does NOT respond to queries
âœ… Lightweight operation

Use Case: Mobile clients, ephemeral nodes
```

### DHT Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DHT Lifecycle                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. INITIALIZATION
   â”œâ”€ Node starts libp2p
   â”œâ”€ DHT service initializes
   â””â”€ Routing table empty (routingTableSize = 0)

2. BOOTSTRAP
   â”œâ”€ Connect to bootstrap peers
   â”œâ”€ Exchange peer information via identify protocol
   â””â”€ Bootstrap peers added to routing table

3. AUTO-POPULATION (TopologyListener)
   â”œâ”€ When peer connects + identify completes
   â”œâ”€ Peer automatically added to routing table
   â”œâ”€ Triggered by peerInfoMapper validation
   â””â”€ routingTableSize increases

4. READY STATE (isReady = true)
   â”œâ”€ Routing table has â‰¥ 1 peer
   â”œâ”€ DHT queries can now succeed
   â””â”€ PUT/GET operations enabled

5. MAINTENANCE
   â”œâ”€ Periodic refresh of routing table
   â”œâ”€ Dead peer removal
   â””â”€ Key replication

6. SHUTDOWN
   â”œâ”€ Stop DHT service
   â”œâ”€ Close all connections
   â””â”€ Clear routing table
```

### TopologyListener Auto-Population

**Critical Mechanism: Automatic Routing Table Population**

When a peer connects and identify completes:  
`TopologyListener â†’ peerInfoMapper â†’ RoutingTable.add()`

```

Connection Flow:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. peer:connect event fires                            â”‚
â”‚ 2. libp2p identify protocol runs                       â”‚
â”‚ 3. Peer's multiaddrs discovered                        â”‚
â”‚ 4. peerInfoMapper validates addresses                  â”‚
â”‚    - passthroughMapper: Allow all (localhost dev)      â”‚
â”‚    - removePrivateAddressesMapper: Public only         â”‚
â”‚ 5. If valid â†’ Peer added to DHT routing table          â”‚
â”‚ 6. routingTableSize increases                          â”‚
â”‚ 7. isReady becomes true when size â‰¥ 1                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why This Matters:**

- No manual routing table management required
- Peers automatically discover each other for DHT operations
- Works with both localhost (dev) and public networks (production)
- Graceful handling of network partitions

---

## Lotus DHT Architecture

### Configuration

```typescript
// P2PCoordinator with DHT enabled
const coordinator = new P2PCoordinator({
  listen: ['/ip4/0.0.0.0/tcp/4001'],
  enableDHT: true, // Enable Kademlia DHT
  enableDHTServer: true, // Server mode (participate)
  dhtProtocol: '/lotus/kad/1.0.0', // Protocol identifier
  dhtPeerInfoMapper: passthroughMapper, // Address filtering
})

await coordinator.start()
```

### DHT Statistics

Real-time monitoring via `getDHTStats()`:

```typescript
interface DHTStats {
  enabled: boolean              // DHT enabled?
  mode: 'client' | 'server'    // Operating mode
  routingTableSize: number     // Peers in routing table
  isReady: boolean             // routingTableSize > 0?
}

// Example usage
const stats = coordinator.getDHTStats()
if (stats.isReady) {
  // Safe to perform DHT operations
  await coordinator.announceResource(...)
}
```

### Resource Management

**Resource Announcement Structure:**

```typescript
interface ResourceAnnouncement<T> {
  resourceId: string // Unique ID (e.g., session ID)
  resourceType: string // Type (e.g., 'musig2-session')
  creatorPeerId: string // Announcing peer
  data: T // Arbitrary metadata
  createdAt: number // Unix timestamp
  expiresAt?: number // Optional expiration
  signature?: Buffer // Optional cryptographic signature
}
```

**Announcement Flow:**

```typescript
// Announce session to DHT
await coordinator.announceResource(
  'musig2-session', // resourceType
  'session-abc123', // resourceId
  {
    signers: ['pubkey1', 'pubkey2', 'pubkey3'],
    message: 'message-hash',
    requiredSigners: 3,
  },
  { ttl: 3600 }, // Optional expiration (1 hour)
)

// Internal process:
// 1. Create ResourceAnnouncement object
// 2. Store in local cache (dhtValues Map)
// 3. If DHT server mode + routing table ready:
//    - Compute key = "resource:musig2-session:session-abc123"
//    - Put key-value in DHT network
//    - Replicate to k closest nodes
```

**Discovery Flow:**

```typescript
// Discover session from DHT network
const session = await coordinator.discoverResource(
  'musig2-session', // resourceType
  'session-abc123', // resourceId
  5000, // timeout (5 seconds)
)

// Internal process:
// 1. Check local cache first (fast path)
// 2. If not found and DHT ready:
//    - Query DHT network for key
//    - Iterate through DHT GET responses
//    - Cache first valid result
//    - Return announcement
```

### Failsafe Mechanisms

**Routing Table Check Before DHT Operations:**

```typescript
// From coordinator.ts:
async announceResource(...) {
  // Store locally first
  this.dhtValues.set(key, announcement)

  // Only propagate to DHT if routing table has peers
  if (this.node.services.kadDHT && this.config.enableDHTServer) {
    const dhtStats = this.getDHTStats()

    if (dhtStats.isReady) {
      // Safe: routing table has peers
      await this._putDHT(keyBytes, valueBytes, 5000)
    }
    // Else: Skip DHT, resource in local cache
  }
}
```

**Why This Pattern?**

- Prevents hanging during startup (routing table still empty)
- Handles network partitions gracefully
- Works with TopologyListener auto-population
- Local cache ensures data availability even without DHT

---

## Visual DHT Structure

### Network Topology

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         Lotus P2P DHT Network               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Node A                Node B                Node C
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Peer ID â”‚          â”‚ Peer ID â”‚          â”‚ Peer ID â”‚
  â”‚ 0x3A... â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ 0x7B... â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ 0x9C... â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â–²                    â–²                     â–²
      â”‚                    â”‚                     â”‚
      â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
      â”‚         â”‚                     â”‚          â”‚
      â”‚         â–¼                     â–¼          â”‚
      â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
      â””â”€â”€â”€â–ºâ”‚ Peer ID â”‚          â”‚ Peer ID â”‚â—„â”€â”€â”€â”€â”€â”˜
           â”‚ 0xD4... â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ 0xE5... â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             Node D                Node E

Each node maintains connections to multiple peers
DHT routing table directs queries to appropriate nodes
```

### Routing Table Structure (Single Node)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Node A (0x3A...)                            â”‚
â”‚                    Routing Table                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ k-bucket[0]:  [Node B: 0x7B...]  â† Distance: 0x49 (closest)    â”‚
â”‚ k-bucket[1]:  [Node E: 0xE5...]  â† Distance: 0xDF              â”‚
â”‚ k-bucket[2]:  [Node C: 0x9C...]  â† Distance: 0xA6              â”‚
â”‚ k-bucket[3]:  []                 â† Empty bucket                â”‚
â”‚ ...                                                            â”‚
â”‚ k-bucket[255]: [Node D: 0xD4...] â† Distance: 0xFE (furthest)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

XOR Distance Calculation:
  Node A: 0x3A... (this node)
  Node B: 0x7B...
  Distance: 0x3A âŠ• 0x7B = 0x49
```

### DHT Key Distribution

```
DHT Key Space (256-bit):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 0x00...                                         0xFF...    â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¤       â”‚
â”‚ â”‚      â”‚      â”‚      â”‚      â”‚      â”‚      â”‚      â”‚        â”‚
â”‚ â”‚ N1   â”‚ N2   â”‚ N3   â”‚ N4   â”‚ N5   â”‚ N6   â”‚ N7   â”‚...     â”‚
â”‚ â”‚      â”‚      â”‚      â”‚      â”‚      â”‚      â”‚      â”‚        â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Keys are uniformly distributed across the ID space
Each node is responsible for keys closest to its ID

Example Resource Keys:
- "resource:musig2-session:abc123" â†’ Hash â†’ 0x8B...
- Node with ID closest to 0x8B... stores this resource
```

### DHT Query Visualization

```
Query: Find "resource:musig2-session:abc123"
Key Hash: 0x8B...

Step 1: Start at Query Node (Node A: 0x3A...)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node A  â”‚ Distance to 0x8B: 0xB1 (far)
â”‚ 0x3A... â”‚ Query: "Who's closest to 0x8B?"
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€â–º Check routing table
     â””â”€â–º Closest known: Node C (0x9C...)

Step 2: Query Node C
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node C  â”‚ Distance to 0x8B: 0x17 (closer)
â”‚ 0x9C... â”‚ Query: "Who's closest to 0x8B?"
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€â–º Check routing table
     â””â”€â–º Closest known: Node F (0x8A...)

Step 3: Query Node F
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node F  â”‚ Distance to 0x8B: 0x01 (very close!)
â”‚ 0x8A... â”‚ Has resource? NO
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ Query: "Who's closest to 0x8B?"
     â”‚
     â”œâ”€â–º Check routing table
     â””â”€â–º Closest known: Node G (0x8B...)

Step 4: Query Node G (Target!)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node G  â”‚ Distance to 0x8B: 0x00 (exact match)
â”‚ 0x8B... â”‚ Has resource? YES! Return value.
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Queries: 3 (O(log n) complexity)
```

---

## DHT State and Lifecycle

### State Machine

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DHT Node State Machine                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    [INITIALIZED]
         â”‚
         â”‚ start()
         â–¼
    [BOOTSTRAPPING] â”€â”€â–º Connect to bootstrap peers
         â”‚
         â”‚ peer:connect + identify
         â–¼
    [POPULATING] â”€â”€â”€â–º TopologyListener adds peers
         â”‚           to routing table
         â”‚
         â”‚ routingTableSize > 0
         â–¼
    [READY] â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DHT operations enabled
         â”‚              - announceResource()
         â”‚              - discoverResource()
         â”‚              - PUT/GET operations
         â”‚
         â”‚ stop()
         â–¼
    [STOPPED]


State Checks:
  const stats = coordinator.getDHTStats()

  if (stats.isReady) {
    // READY state: safe to use DHT
  } else {
    // BOOTSTRAPPING/POPULATING: use local cache only
  }
```

### Local Cache vs DHT Network

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Resource Storage Architecture                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    announceResource()
                            â”‚
                            â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  1. Store in Local Cache (ALWAYS)    â”‚
         â”‚     dhtValues.set(key, announcement) â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ DHT Server Mode?        â”‚
              â”‚ Routing Table Ready?    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚              â”‚
                 YES â”‚              â”‚ NO
                     â–¼              â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   [Skip DHT]
         â”‚ 2. Propagate to  â”‚   (Local Only)
         â”‚    DHT Network   â”‚
         â”‚    - PUT to DHT  â”‚
         â”‚    - Replicate   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


                   discoverResource()
                            â”‚
                            â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  1. Check Local Cache (Fast Path)    â”‚
         â”‚     cached = dhtValues.get(key)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚              â”‚
                 Found â”‚            â”‚ Not Found
                     â–¼              â–¼
              [Return]      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚ DHT Enabled?     â”‚
                            â”‚ Routing Ready?   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚        â”‚
                              YES â”‚        â”‚ NO
                                  â–¼        â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  [Return null]
                      â”‚ 2. Query DHT â”‚
                      â”‚    Network   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                      [Return result]
```

### DHT Health Monitoring

```typescript
// Real-time DHT health check
function checkDHTHealth(coordinator: P2PCoordinator) {
  const stats = coordinator.getDHTStats()

  console.log('DHT Health Report:')
  console.log('  Enabled:', stats.enabled)
  console.log('  Mode:', stats.mode)
  console.log('  Routing Table Size:', stats.routingTableSize)
  console.log('  Ready:', stats.isReady)

  if (!stats.isReady) {
    console.warn('âš ï¸  DHT not ready - waiting for peers')
  } else {
    console.log('âœ… DHT operational')
  }
}

// Usage
setInterval(() => checkDHTHealth(coordinator), 10000)
```

---

## MuSig2 Coordination via DHT

### Overview

MuSig2 multi-signature coordination uses a **three-phase architecture** that solves the chicken-and-egg problem of peer discovery:

1. **Phase 0: Signer Advertisement** - Wallets announce their public keys and availability
2. **Phase 1: Matchmaking** - Users discover available signers matching their criteria
3. **Phase 2: Signing Request** - Create requests with discovered public keys
4. **Phase 3: Dynamic Session Building** - Participants join, session builds when ALL join (n-of-n)

**Hybrid Architecture:**

```
DHT: Signer advertisements, signing request discovery (offline/historical)
GossipSub: Real-time event-driven discovery via pub/sub topics
Direct P2P: Cryptographic material exchange (nonces, partial signatures)
Broadcast: Advertisement and request announcements to connected peers
```

**Discovery Mechanisms:**

1. **GossipSub (Real-Time)**:
   - Topic-based pub/sub: `musig2:signers:{transactionType}`
   - Instant notifications (10-100ms latency)
   - Subscribe before publish (true pub/sub semantics)
   - Powered by `@libp2p/gossipsub` (Ethereum 2.0 standard)

2. **DHT (Offline/Historical)**:
   - Query pre-existing advertisements
   - Persistent storage across time
   - 500-2000ms latency

3. **P2P Broadcast (Direct Messaging)**:
   - Direct peer-to-peer announcements
   - 50-200ms latency
   - Requires peer connections

### Security: Signature Verification at Receipt

**Alice cannot trust Zoe or any intermediary** - she must verify cryptographic proof locally:

```typescript
// When Alice receives an advertisement (via DHT, GossipSub, or P2P):

// 1. Extract signature from advertisement
const { signature, publicKey, peerId, multiaddrs, criteria } = advertisement

// 2. Verify signature BEFORE trusting
const isValid = coordinator.verifyAdvertisementSignature(advertisement)

if (!isValid) {
  // Reject! Possible attack or corrupted data
  console.warn('Invalid advertisement signature - dropping')
  return
}

// 3. Signature valid â†’ cryptographic proof established
//    - Bob owns the advertised public key (only he could sign)
//    - Multiaddrs are authentic (part of signed data)
//    - No MITM possible (signature would break)

// 4. Safe to connect
await coordinator.connectToSigner(advertisement)
```

**Verification Points:**

- âœ… **GossipSub handler**: Verifies before emitting `SIGNER_DISCOVERED`
- âœ… **P2P broadcast handler**: Verifies before emitting `SIGNER_DISCOVERED`
- âœ… **DHT query**: Verifies when deserializing from DHT
- âœ… **No challenge-response needed**: Signature IS the proof!

### Why Three Phases?

**The Problem**: Traditional approach assumes you know all signers upfront:

- âŒ Can't create transaction without knowing public keys
- âŒ Can't discover public keys without a way for wallets to advertise
- âŒ Chicken-and-egg: Need keys to create session, need session to find keys

**The Solution**: Phase 0 breaks the cycle:

- âœ… **Phase 0**: Wallets advertise "I'm available with this public key"
- âœ… **Phase 1**: Users discover signers: "Find me 2 signers for a spend transaction"
- âœ… **Phase 2**: Create transaction with discovered keys, announce signing request
- âœ… **Phase 3**: Participants discover they're needed, join dynamically

### Three-Phase Flow Detailed

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Phase 0: Signer Advertisement                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Wallet A (Available for Signing):
  1. advertiseSigner(myPrivateKey, criteria)
     â”œâ”€ Criteria: {transactionTypes: ['spend', 'swap']}
     â”œâ”€ Create Schnorr signature over advertisement
     â””â”€ Metadata: {nickname: "AliceWallet", fees: 0}

  2. Announce to DHT (Multi-Index)
     â”œâ”€ musig2-signer:type:spend:pubkeyA
     â”œâ”€ musig2-signer:type:swap:pubkeyA
     â””â”€ musig2-signer:all:pubkeyA

  3. Broadcast to P2P
     â””â”€ SIGNER_ADVERTISEMENT â†’ all connected peers

Wallet B, C, ... (Also Available):
  â””â”€ Same process, different public keys

DHT Network:
  â”œâ”€ Indexed by transaction type: "type:spend" â†’ [pubkeyA, pubkeyB]
  â”œâ”€ Indexed by transaction type: "type:swap" â†’ [pubkeyA, pubkeyC]
  â””â”€ Global index: "all" â†’ [pubkeyA, pubkeyB, pubkeyC]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Phase 1: Matchmaking & Discovery                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User (Needs 3-of-3 MuSig2 for 5 XPI Spend):
  1. findAvailableSigners({transactionType: 'spend', minAmount: 5M})
     â”œâ”€ Query local cache (from broadcasts)
     â”œâ”€ Apply filters
     â””â”€ Returns: [SignerA, SignerB, SignerC]

  2. User selects 2 other signers
     â””â”€ Selected: [AliceWallet (pubkeyA), BobWallet (pubkeyB)]

  3. Now knows public keys!
     â””â”€ requiredKeys = [myKey, pubkeyA, pubkeyB] (all 3 must sign)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Phase 2: Signing Request Creation                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User (Creates Transaction & Request):
  1. Create transaction
     â”œâ”€ Build transaction with requiredKeys
     â”œâ”€ Generate sighash/message
     â””â”€ Transaction ready for signing

  2. announceSigningRequest(requiredKeys, message, myPrivateKey)
     â”œâ”€ requestId: hash(message + keys + timestamp)
     â”œâ”€ requiredKeys: 3 keys (ALL must sign - MuSig2 = n-of-n)
     â”œâ”€ metadata: {transactionHex, amount: 5M, type: 'spend'}
     â””â”€ creatorSignature: Schnorr signature

  3. Announce to DHT (Multi-Index by Required Keys)
     â”œâ”€ musig2-signing-request:requestId:myKey
     â”œâ”€ musig2-signing-request:requestId:pubkeyA  â† AliceWallet can find
     â””â”€ musig2-signing-request:requestId:pubkeyB  â† BobWallet can find

  4. Broadcast to P2P
     â””â”€ SIGNING_REQUEST â†’ all connected peers

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Phase 3: Dynamic Session Building (n-of-n MuSig2)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AliceWallet (Discovers They're Needed):
  1. Receives SIGNING_REQUEST broadcast
     â””â”€ Or: findSigningRequestsForMe(myPublicKey)

  2. Checks: "Is my public key required?"
     â””â”€ Yes! pubkeyA is in requiredPublicKeys

  3. Validates request
     â”œâ”€ Verify creator signature
     â”œâ”€ Check transaction details (amount, type)
     â””â”€ User approves signing

  4. joinSigningRequest(requestId, myPrivateKey)
     â”œâ”€ Create participation signature
     â”œâ”€ Broadcast PARTICIPANT_JOINED
     â””â”€ Add self to participants map

BobWallet (Also Discovers & Joins):
  â””â”€ Same process, joins independently

Session State (Dynamic Building):
  â”œâ”€ Initially: 1/3 participants (creator only)
  â”œâ”€ AliceWallet joins: 2/3 participants
  â””â”€ BobWallet joins: 3/3 participants â†’ All joined! (3-of-3 MuSig2)

When ALL Participants Joined:
  1. _createMuSigSessionFromRequest()
     â”œâ”€ Create local MuSig session
     â”œâ”€ Phase changes: 'waiting' â†’ 'ready'
     â””â”€ Emit SESSION_READY event

  2. Proceed with MuSig2 protocol
     â”œâ”€ Round 1: Nonce exchange
     â”œâ”€ Round 2: Partial signature exchange
     â””â”€ Finalization: Aggregate signature
```

### Session Discovery Pattern

**Three-Phase Solution:**

The three-phase architecture solves the discoverability problem:

- âœ… **Phase 0**: Wallets advertise their public keys proactively
- âœ… **Phase 1**: Users discover available signers by criteria
- âœ… **Phase 2**: Signing requests indexed by required public keys
- âœ… **Phase 3**: Automatic discovery - wallets find requests needing their key

**Discovery Patterns:**

```typescript
// Pattern 1: Advertise your availability (Phase 0)
await musig2Coordinator.advertiseSigner(
  myPrivateKey,
  {
    transactionTypes: ['spend', 'swap'],
    minAmount: 1_000_000, // 1 XPI
    maxAmount: 100_000_000, // 100 XPI
  },
  {
    ttl: 24 * 60 * 60 * 1000, // 24 hours
    metadata: {
      nickname: 'MyWallet',
      fees: 0,
    },
  },
)

// Pattern 2: Find available signers (Phase 1)
const availableSigners = await musig2Coordinator.findAvailableSigners({
  transactionType: 'spend',
  minAmount: 5_000_000, // 5 XPI transaction
  maxResults: 10,
})

console.log(`Found ${availableSigners.length} available signers`)
// User selects from list

// Pattern 3: Create signing request with discovered keys (Phase 2)
const selectedSigners = [availableSigners[0], availableSigners[1]]
const requiredKeys = [
  myPrivateKey.publicKey,
  ...selectedSigners.map(s => s.publicKey),
]

const requestId = await musig2Coordinator.announceSigningRequest(
  requiredKeys,
  transactionSighash,
  myPrivateKey,
  {
    metadata: {
      transactionHex: tx.toHex(),
      amount: 5_000_000,
      transactionType: 'spend',
      description: '3-of-3 MuSig2 - all must sign',
    },
  },
)

// Pattern 4: Discover requests needing your key (Phase 3)
const myRequests = await musig2Coordinator.findSigningRequestsForMe(
  myPrivateKey.publicKey,
)

console.log(`You have ${myRequests.length} pending signing requests`)

// Pattern 5: Join a discovered request (Phase 3)
for (const request of myRequests) {
  // User approves
  await musig2Coordinator.joinSigningRequest(request.requestId, myPrivateKey)
  // Session automatically created when ALL participants join (n-of-n)
}

// Pattern 6: Event-based discovery (automatic)
coordinator.on('signing-request:received', request => {
  if (isMyKeyRequired(request, myPublicKey)) {
    showNotification(`Signing request: ${request.metadata?.amount} XPI`)
  }
})

coordinator.on('session:ready', sessionId => {
  // All participants joined (n-of-n), session ready for signing
  console.log('Session ready for nonce exchange')
})
```

**Key Improvements:**

- âœ… No out-of-band communication needed for connected peers
- âœ… Automatic discovery via broadcasts and DHT indexing
- âœ… Multi-index DHT enables efficient filtering
- âœ… Dynamic session building (ALL participants must join for MuSig2 n-of-n)
- âœ… Event-driven notifications for real-time updates
- âš ï¸ **Note**: MuSig2 = n-of-n only (all must sign). For m-of-n use FROST or Taproot scripts

### Complete MuSig2 Coordination Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               MuSig2 P2P Coordination Flow                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 0: Session Setup
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Signer 1   â”‚ (Creator)
â”‚  0x3A...    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 1. announceSession()
       â”œâ”€â”€â–º Store in DHT: "resource:musig2-session:abc123"
       â”‚    Data: {signers, message, creatorSignature}
       â”‚
       â”‚ 2. Broadcast SESSION_ANNOUNCE
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                  â”‚
Phase 1: Session Join                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Signer 2   â”‚  â”‚  Signer 3   â”‚  â”‚  Signer N   â”‚
â”‚  0x7B...    â”‚  â”‚  0x9C...    â”‚  â”‚  0xE5...    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚                â”‚
       â”‚ 3. Receive SESSION_ANNOUNCE    â”‚
       â”‚    (via P2P broadcast or DHT)  â”‚
       â”‚                â”‚                â”‚
       â”‚ 4. Validate    â”‚                â”‚
       â”‚    - Creator signature          â”‚
       â”‚    - Am I in signers list?      â”‚
       â”‚                â”‚                â”‚
       â”‚ 5. Send SESSION_JOIN to Signer 1
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       â”‚   SESSION_JOIN â”‚   SESSION_JOIN â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
                                         â”‚
Phase 2: Nonce Exchange                 â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 6. All signers joined
       â”‚    Broadcast NONCE_SHARE
       â–¼
All Signers Exchange Nonces (P2P Messages)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     NONCE_SHARE      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Signer1 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Signer2 â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚         NONCE_SHARE            â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                 â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                 â”‚ Signer3 â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 3: Partial Signature Exchange
All Signers Exchange Partial Signatures (P2P Messages)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  PARTIAL_SIG_SHARE   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Signer1 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Signer2 â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚     PARTIAL_SIG_SHARE          â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                 â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                 â”‚ Signer3 â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 4: Finalization
Each signer:
  1. Collects all partial signatures
  2. Aggregates into final signature
  3. Broadcasts SIGNATURE_FINALIZED
  4. Session complete! ðŸŽ‰
```

### Session Announcement Data Structure

```typescript
// Data stored in DHT
interface SessionAnnouncementData {
  sessionId: string // "abc123"
  signers: PublicKey[] // [pubkey1, pubkey2, pubkey3]
  creatorPeerId: string // "12D3Koo..."
  creatorIndex: number // 0 (first signer)
  message: Buffer // Message to sign
  requiredSigners: number // 3 (all must sign - MuSig2 = n-of-n)
  createdAt: number // 1730419200000
  expiresAt?: number // 1730422800000 (optional)

  // Security
  creatorSignature: Buffer // Schnorr signature over announcement

  // Coordinator election (optional)
  election?: {
    coordinatorIndex: number // Elected coordinator (0-2)
    electionMethod: string // 'hash-based'
    electionProof: string // Deterministic proof
  }
}

// DHT Key
const key = 'resource:musig2-session:abc123'

// Storage
coordinator.announceResource('musig2-session', 'abc123', data)
```

---

## Network Communication Patterns

### Communication Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Communication Layers                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Layer 4: Protocol Logic (MuSig2)
         â”œâ”€ Session management
         â”œâ”€ Cryptographic operations
         â””â”€ State machine

Layer 3: P2P Messaging (P2PCoordinator)
         â”œâ”€ sendTo(peerId, message)
         â”œâ”€ broadcast(message)
         â””â”€ Protocol routing

Layer 2: DHT Operations (libp2p kad-dht)
         â”œâ”€ announceResource()
         â”œâ”€ discoverResource()
         â””â”€ Routing table management

Layer 1: Transport (libp2p)
         â”œâ”€ TCP connections
         â”œâ”€ WebSocket connections
         â”œâ”€ Stream multiplexing (mplex)
         â””â”€ Encryption (Noise protocol)

Layer 0: Network (IP)
         â””â”€ Internet connectivity
```

### Message Types

**1. DHT Operations (Layer 2)**

```
DHT PUT:
  Purpose: Store session announcement
  Scope: Network-wide (k nodes)
  Performance: Slower (multiple hops)
  Use Case: Session discovery

DHT GET:
  Purpose: Retrieve session announcement
  Scope: Network-wide (multiple queries)
  Performance: Slower (O(log n) hops)
  Use Case: Find existing sessions
```

**2. Direct P2P Messages (Layer 3)**

```
sendTo(peerId, message):
  Purpose: Direct communication
  Scope: Single peer
  Performance: Fast (single hop)
  Use Case: Nonce/signature exchange

broadcast(message):
  Purpose: Notify all participants
  Scope: All connected peers
  Performance: Fast (parallel)
  Use Case: Session announcements, phase transitions
```

### MuSig2 Message Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           MuSig2 Message Types and Flows                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DHT Announcements:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SESSION_ANNOUNCE (DHT)  â”‚ â”€â”€â–º Stored in DHT
â”‚  - sessionId             â”‚     Key: resource:musig2-session:abc123
â”‚  - signers list          â”‚     Replication: k nodes
â”‚  - message hash          â”‚     TTL: 1 hour (default)
â”‚  - creator signature     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

P2P Messages (Direct):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SESSION_JOIN            â”‚ â”€â”€â–º Direct to creator
â”‚  - sessionId             â”‚     Confirms participation
â”‚  - signerIndex           â”‚
â”‚  - publicKey             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NONCE_SHARE             â”‚ â”€â”€â–º Broadcast to all signers
â”‚  - sessionId             â”‚     Contains [R1, R2] points
â”‚  - signerIndex           â”‚     65 bytes total
â”‚  - publicNonce [R1, R2]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PARTIAL_SIG_SHARE       â”‚ â”€â”€â–º Broadcast to all signers
â”‚  - sessionId             â”‚     Contains partial signature
â”‚  - signerIndex           â”‚     32 bytes
â”‚  - partialSig (BN)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SIGNATURE_FINALIZED     â”‚ â”€â”€â–º Broadcast to all signers
â”‚  - sessionId             â”‚     Final aggregated signature
â”‚  - finalSignature        â”‚     64 bytes (Schnorr)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Message Routing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Message Routing Logic                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Incoming Message:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ libp2p stream    â”‚
  â”‚ '/lotus/message' â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ P2PCoordinator   â”‚
  â”‚ _handleIncoming  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â–º Deserialize message
           â”œâ”€â–º Validate structure
           â”œâ”€â–º Check for duplicate (seenMessages)
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Route by         â”‚
  â”‚ message.protocol â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â–º protocol='musig2' â”€â”€â–º MuSig2P2PProtocolHandler
           â”œâ”€â–º protocol='coinjoin' â”€â”€â–º CoinJoinProtocolHandler
           â””â”€â–º protocol=undefined â”€â”€â–º Generic handler

MuSig2P2PProtocolHandler:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Route by         â”‚
  â”‚ message.type     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â–º SESSION_ANNOUNCE â”€â”€â–º _handleSessionAnnounce()
           â”œâ”€â–º SESSION_JOIN     â”€â”€â–º _handleSessionJoin()
           â”œâ”€â–º NONCE_SHARE      â”€â”€â–º _handleNonceShare()
           â”œâ”€â–º PARTIAL_SIG      â”€â”€â–º _handlePartialSigShare()
           â””â”€â–º ...

MuSig2P2PCoordinator:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Process message  â”‚
  â”‚ Update session   â”‚
  â”‚ Emit events      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technical Implementation Details

### Code: DHT Initialization

```typescript
// From coordinator.ts:start()

// Auto-detect peerInfoMapper based on environment
let peerInfoMapper = this.config.dhtPeerInfoMapper

if (!peerInfoMapper) {
  const listenAddrs = this.config.listen || ['/ip4/0.0.0.0/tcp/0']
  const isLocalhost = listenAddrs.some(
    addr => addr.includes('127.0.0.1') || addr.includes('localhost'),
  )

  if (isLocalhost) {
    // Development: allow private addresses (127.0.0.1)
    peerInfoMapper = passthroughMapper
  } else {
    // Production: filter private addresses for security
    peerInfoMapper = removePrivateAddressesMapper
  }
}

// Create libp2p with DHT
const config = {
  addresses: {
    listen: this.config.listen || ['/ip4/0.0.0.0/tcp/0'],
  },
  transports: [tcp(), webSockets()],
  connectionEncrypters: [noise()],
  streamMuxers: [mplex()],
  services: {
    identify: identify(),
    ping: ping(),
    kadDHT: kadDHT({
      protocol: this.config.dhtProtocol || '/lotus/kad/1.0.0',
      clientMode: !(this.config.enableDHTServer ?? false),
      peerInfoMapper,
    }),
  },
}

this.node = await createLibp2p(config)
await this.node.start()
```

### Code: Resource Announcement

```typescript
// From coordinator.ts:announceResource()

async announceResource<T>(
  resourceType: string,
  resourceId: string,
  data: T,
  options?: { ttl?: number; expiresAt?: number }
): Promise<void> {
  const announcement: ResourceAnnouncement<T> = {
    resourceId,
    resourceType,
    creatorPeerId: this.node.peerId.toString(),
    data,
    createdAt: Date.now(),
    expiresAt: options?.expiresAt,
  }

  // 1. Store locally (ALWAYS)
  const key = this._makeResourceKey(resourceType, resourceId)
  this.dhtValues.set(key, announcement)

  // 2. Propagate to DHT network (if ready)
  if (this.node.services.kadDHT && this.config.enableDHTServer) {
    const dhtStats = this.getDHTStats()

    if (dhtStats.isReady) {
      // Safe: routing table has peers
      const dht = this.node.services.kadDHT as KadDHT
      const keyBytes = uint8ArrayFromString(key)
      const valueBytes = uint8ArrayFromString(JSON.stringify(announcement))

      await this._putDHT(keyBytes, valueBytes, 5000)
    }
    // Else: routing table empty, skip DHT propagation
  }

  this.emit('resource:announced', announcement)
}

private _makeResourceKey(type: string, id: string): string {
  return `resource:${type}:${id}`
}
```

### Code: Resource Discovery

```typescript
// From coordinator.ts:discoverResource()

async discoverResource(
  resourceType: string,
  resourceId: string,
  timeoutMs: number = 5000
): Promise<ResourceAnnouncement | null> {
  const key = this._makeResourceKey(resourceType, resourceId)

  // 1. Check local cache first (fast path)
  const cached = this.dhtValues.get(key)
  if (cached && (!cached.expiresAt || cached.expiresAt > Date.now())) {
    return cached
  }

  // 2. Query DHT network (if ready)
  if (this.node?.services.kadDHT) {
    const dhtStats = this.getDHTStats()

    if (dhtStats.isReady) {
      // Routing table has peers - safe to query
      return this._queryDHT(key, timeoutMs)
    }
  }

  return null
}

// Internal DHT query with timeout
private async _queryDHT(
  key: string,
  timeoutMs: number
): Promise<ResourceAnnouncement | null> {
  const dht = this.node.services.kadDHT as KadDHT
  const keyBytes = uint8ArrayFromString(key)
  const controller = new AbortController()

  const timeout = setTimeout(() => controller.abort(), timeoutMs)

  try {
    let eventCount = 0
    const maxEvents = 20  // Prevent infinite iteration

    for await (const event of dht.get(keyBytes, { signal: controller.signal })) {
      eventCount++

      if (event.name === 'VALUE') {
        const valueStr = uint8ArrayToString(event.value)
        const announcement = JSON.parse(valueStr)

        // Cache it
        this.dhtValues.set(key, announcement)
        clearTimeout(timeout)
        return announcement
      }

      if (eventCount >= maxEvents) break
    }
  } catch (error) {
    if (error.name !== 'AbortError') {
      console.error('DHT query error:', error)
    }
  } finally {
    clearTimeout(timeout)
  }

  return null
}
```

### Code: MuSig2 Session Announcement

```typescript
// From musig2/coordinator.ts:announceSession()

async announceSession(
  signers: PublicKey[],
  myPrivateKey: PrivateKey,
  message: Buffer,
  options?: { requiredSigners?: number }
): Promise<string> {
  // 1. Create local session
  const session = this.sessionManager.createSession(
    signers,
    myPrivateKey,
    message,
    options
  )

  // 2. Sign announcement for authenticity
  const announcementData = Buffer.concat([
    Buffer.from(session.sessionId),
    message,
    ...signers.map(pk => pk.toBuffer()),
  ])
  const creatorSignature = Schnorr.sign(myPrivateKey, announcementData)

  // 3. Prepare announcement metadata
  const metadata: SessionAnnouncementData = {
    sessionId: session.sessionId,
    signers,
    creatorPeerId: this.peerId,
    creatorIndex: session.mySignerIndex,
    message,
    requiredSigners: options?.requiredSigners || signers.length,
    createdAt: Date.now(),
    expiresAt: Date.now() + this.musig2Config.sessionTimeout,
    creatorSignature,
  }

  // 4. Announce to DHT (if enabled)
  if (this.musig2Config.enableSessionDiscovery) {
    await this.announceResource(
      this.musig2Config.sessionResourceType,  // 'musig2-session'
      session.sessionId,
      metadata
    )
  }

  // 5. Broadcast to P2P network
  const payload: SessionAnnouncementPayload = {
    sessionId: session.sessionId,
    signers: signers.map(pk => pk.toString()),
    creatorIndex: session.mySignerIndex,
    message: message.toString('hex'),
    requiredSigners: metadata.requiredSigners,
    creatorSignature: creatorSignature.toString('hex'),
  }

  await this.broadcast({
    type: MuSig2MessageType.SESSION_ANNOUNCE,
    from: this.peerId,
    payload,
    timestamp: Date.now(),
    messageId: generateId(),
    protocol: 'musig2',
  })

  return session.sessionId
}
```

### Code: Session Discovery

```typescript
// From musig2/coordinator.ts

// Discovery Pattern 1: Query all local sessions
async findAvailableSessions(): Promise<SessionAnnouncementData[]> {
  const sessions = this.getLocalResources('musig2-session')

  return sessions
    .map(res => res.data as SessionAnnouncementData)
    .filter(session => {
      // Filter: not expired
      if (session.expiresAt && session.expiresAt < Date.now()) {
        return false
      }
      // Filter: I'm a signer
      const myPubKey = this.myPublicKey.toString()
      return session.signers.some(pk => pk.toString() === myPubKey)
    })
}

// Discovery Pattern 2: Query specific session from DHT
async findSession(sessionId: string): Promise<SessionAnnouncementData | null> {
  const resource = await this.discoverResource(
    'musig2-session',
    sessionId,
    5000  // 5 second timeout
  )

  if (!resource) return null

  const session = resource.data as SessionAnnouncementData

  // Validate creator signature
  if (session.creatorSignature) {
    const announcementData = Buffer.concat([
      Buffer.from(session.sessionId),
      session.message,
      ...session.signers.map(pk => pk.toBuffer()),
    ])

    const creatorPubKey = session.signers[session.creatorIndex]
    const isValid = Schnorr.verify(
      creatorPubKey,
      announcementData,
      session.creatorSignature
    )

    if (!isValid) {
      throw new Error('Invalid creator signature - DHT poisoning detected')
    }
  }

  return session
}
```

---

## Performance and Scaling

### DHT Performance Characteristics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DHT Performance Metrics                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Lookup Complexity: O(log n)
  - Network with 1,000 nodes: ~10 hops
  - Network with 1,000,000 nodes: ~20 hops
  - Network with 1,000,000,000 nodes: ~30 hops

Storage Redundancy: k nodes (default k=20)
  - Each key stored on 20 nodes
  - Tolerates 19 node failures
  - Increases availability

Query Latency:
  - Local cache hit: <1ms
  - DHT query (small network): 100-500ms
  - DHT query (large network): 500-2000ms
  - Timeout: 5000ms (configurable)

Bandwidth:
  - Announcement: ~1KB per resource
  - Query: ~500 bytes per hop
  - Negligible for typical use
```

### Scaling Considerations

**1. Network Size**

```
Small Network (< 10 nodes):
  âœ… Local cache sufficient
  âœ… Broadcast announcements work well
  âš ï¸  DHT may not be necessary

Medium Network (10-1000 nodes):
  âœ… DHT provides efficient discovery
  âœ… Routing table well-populated
  âœ… O(log n) benefit apparent

Large Network (> 1000 nodes):
  âœ… DHT essential for scalability
  âœ… Broadcast becomes inefficient
  âœ… Full Kademlia benefits
```

**2. Session Volume**

```
Low Volume (< 100 sessions/hour):
  âœ… DHT handles easily
  âœ… No special optimization needed

Medium Volume (100-1000 sessions/hour):
  âœ… Local cache provides fast path
  âœ… DHT handles discovery
  âš ï¸  Monitor routing table size

High Volume (> 1000 sessions/hour):
  âœ… Local cache critical
  âœ… Consider session TTL reduction
  âœ… Implement cleanup automation
  âš ï¸  May need DHT server mode on multiple nodes
```

### Optimization Strategies

**1. Local Cache First**

```typescript
// Always check cache before DHT query
const cached = coordinator.getLocalResources('musig2-session')
if (cached.length > 0) {
  // Use cached sessions (fast)
} else {
  // Fall back to DHT query (slower)
  const session = await coordinator.discoverResource(...)
}
```

**2. Session Expiration**

```typescript
// Set reasonable TTL to prevent stale data
await coordinator.announceResource(
  'musig2-session',
  sessionId,
  data,
  { expiresAt: Date.now() + 3600_000 }, // 1 hour
)
```

**3. Automatic Cleanup**

```typescript
// Periodic cleanup of expired sessions
setInterval(() => {
  coordinator.cleanup() // Removes expired DHT entries
}, 60_000) // Every minute
```

**4. DHT Server Mode Strategy**

```typescript
// Long-running nodes: Server mode
const serverNode = new P2PCoordinator({
  listen: ['/ip4/0.0.0.0/tcp/4001'],
  enableDHT: true,
  enableDHTServer: true, // Participate in DHT network
})

// Ephemeral clients: Client mode
const clientNode = new P2PCoordinator({
  listen: ['/ip4/0.0.0.0/tcp/0'],
  enableDHT: true,
  enableDHTServer: false, // Query only
})
```

### Monitoring and Debugging

```typescript
// DHT health monitoring
function monitorDHT(coordinator: P2PCoordinator) {
  const stats = coordinator.getDHTStats()
  const p2pStats = coordinator.getStats()

  console.log('=== DHT Status ===')
  console.log('Enabled:', stats.enabled)
  console.log('Mode:', stats.mode)
  console.log('Routing Table Size:', stats.routingTableSize)
  console.log('Ready:', stats.isReady)
  console.log('Local Records:', p2pStats.dht.localRecords)
  console.log('Connected Peers:', p2pStats.peers.connected)
  console.log('Multiaddrs:', p2pStats.multiaddrs)

  if (!stats.isReady) {
    console.warn('âš ï¸  DHT not ready - routing table empty')
    console.warn('    - Check bootstrap peers')
    console.warn('    - Check peerInfoMapper configuration')
    console.warn('    - Wait for peer connections')
  }
}

// Run every 10 seconds
setInterval(() => monitorDHT(coordinator), 10000)
```

---

## Current Limitations and Future Improvements

### Limitation: No Session Enumeration

**Problem:**

The Kademlia DHT cannot enumerate all keys matching a pattern. This creates a discoverability challenge:

```typescript
// âŒ Not possible with DHT
const allSessions = await coordinator.findAllSessions()

// âœ… Only works if you know the exact session ID
const session = await coordinator.discoverResource('musig2-session', 'abc123')
```

**Current Workarounds:**

1. **Out-of-Band Communication**: Share session IDs via email, chat, QR codes
2. **Deep Links**: `lotus://musig2/join/abc123`
3. **Local Cache**: Query sessions you've previously heard about

**Impact:**

- âš ï¸ Users must manually share session IDs
- âš ï¸ No automatic session discovery for newcomers
- âš ï¸ Cannot browse "available sessions"

### Recommended Improvements

**1. Add P2P Broadcast of Session Announcements**

Enhance `createSession()` to broadcast to all connected peers:

```typescript
// After DHT announcement, add:
await this._broadcastSessionAnnouncement(session, myPrivateKey)

// New method:
private async _broadcastSessionAnnouncement(
  session: MuSigSession,
  creatorPrivateKey: PrivateKey,
): Promise<void> {
  const payload: SessionAnnouncementPayload = {
    sessionId: session.sessionId,
    signers: session.signers.map(pk => pk.toString()),
    creatorIndex: session.myIndex,
    message: session.message.toString('hex'),
    requiredSigners: session.signers.length,
    creatorSignature: this._signSessionAnnouncement(...).toString('hex'),
  }

  // Broadcast to all connected peers
  await this.broadcast({
    type: MuSig2MessageType.SESSION_ANNOUNCE,
    from: this.peerId,
    payload,
    timestamp: Date.now(),
    messageId: generateId(),
    protocol: 'musig2',
  })
}
```

**Benefits:**

- âœ… Connected wallets automatically learn about new sessions
- âœ… Builds local cache for session browsing
- âœ… No out-of-band communication needed for connected peers
- âœ… DHT still provides backup for late-joining nodes

**2. Add Session Discovery API**

Add a user-facing method to query available sessions:

```typescript
/**
 * Find available MuSig2 sessions from local cache
 *
 * @param filters - Optional filters
 * @returns Array of session announcements
 */
async findAvailableSessions(filters?: {
  includeExpired?: boolean
  myPublicKey?: PublicKey
  minSigners?: number
  maxSigners?: number
}): Promise<SessionAnnouncementData[]> {
  const resources = this.getLocalResources('musig2-session')

  return resources
    .map(res => res.data as SessionAnnouncementData)
    .filter(session => {
      // Apply filters
      if (!filters?.includeExpired && session.expiresAt < Date.now()) {
        return false
      }
      if (filters?.myPublicKey) {
        const myKey = filters.myPublicKey.toString()
        if (!session.signers.some(pk => pk.toString() === myKey)) {
          return false
        }
      }
      // ... more filters
      return true
    })
}
```

**Usage:**

```typescript
// Wallet UI: "Show available sessions"
const sessions = await musig2Coordinator.findAvailableSessions({
  myPublicKey: myPrivateKey.publicKey,
  includeExpired: false,
})

console.log(`Found ${sessions.length} sessions I can join`)
```

**3. Implement Session Browser**

For wallet UIs, add event-driven session discovery:

```typescript
// Listen for new session announcements
coordinator.on('session:discovered', (session: SessionAnnouncementData) => {
  // Update UI: "New session available: abc123"
  if (isEligibleSigner(session, myPublicKey)) {
    showNotification(`New MuSig2 session: ${session.sessionId}`)
  }
})
```

### Alternative: Specialized Discovery Protocol

For large-scale deployments, consider implementing a separate discovery protocol:

**Option A: DHT-Based Registry Pattern**

Store a registry of session IDs at a well-known key:

```typescript
// Registry key: "musig2-session-registry"
// Value: ["abc123", "xyz789", ...]

// Coordinator periodically updates registry
await coordinator.announceResource('musig2-session-registry', 'global', {
  sessions: Array.from(activeSessions.keys()),
})

// Wallets query registry
const registry = await coordinator.discoverResource(
  'musig2-session-registry',
  'global',
)
// Then query each session individually
```

**Drawbacks:**

- Registry becomes a bottleneck
- Requires coordination for updates
- Doesn't scale well

**Option B: Gossip Protocol**

Implement a gossip-based discovery layer on top of DHT:

```typescript
// Peers periodically exchange session lists
// "I know about: [abc123, xyz789]"
// "I know about: [def456, ghi101]"
// Now both peers know about 4 sessions
```

**Complexity:**

- More complex to implement
- Adds network overhead
- Better for very large networks

### Recommended Approach

**For Most Use Cases:**

**Phase 1**: Add P2P broadcast + local cache (simple, effective)  
**Phase 2**: Add `findAvailableSessions()` API (user-friendly)  
**Phase 3**: Consider specialized protocol only if scaling issues arise

**Implementation Priority:**

1. âœ… **High**: P2P broadcast of session announcements
2. âœ… **High**: `findAvailableSessions()` method
3. âš ï¸ **Medium**: Session browser UI/events
4. ðŸ”œ **Low**: Specialized discovery protocol (only if needed)

## Summary

### Key Takeaways

**DHT Architecture:**

- âœ… Kademlia DHT provides O(log n) scalability
- âœ… libp2p kad-dht is production-ready and battle-tested
- âœ… TopologyListener auto-populates routing table
- âœ… Local cache provides fast path for common queries
- âš ï¸ **Cannot enumerate all keys** - designed for exact lookups only

**MuSig2 Coordination:**

- âœ… **Three-phase architecture** solves peer discovery problem
- âœ… **Phase 0**: Signer advertisement enables public key discovery
- âœ… **Phase 1**: Matchmaking finds signers by criteria
- âœ… **Phase 2**: Signing requests indexed by required keys
- âœ… **Phase 3**: Dynamic session building (ALL must join - n-of-n)
- âœ… DHT multi-indexing for efficient discovery
- âœ… Direct P2P messages for cryptographic material
- âœ… Broadcast announcements to connected peers
- âœ… Automatic failsafe prevents hanging during startup
- âœ… **No out-of-band communication needed** for connected wallets
- âš ï¸ **MuSig2 = n-of-n only** (for m-of-n use FROST or Taproot script paths)

**Best Practices:**

1. **Always check `getDHTStats().isReady` before DHT operations**
2. **Advertise signer availability** with appropriate criteria and TTL
3. **Use local cache first, DHT as fallback**
4. **Set reasonable TTLs** (24 hours for advertisements, 1-2 hours for requests)
5. **Enable DHT server mode on long-running nodes**
6. **Monitor routing table size for health**
7. **Implement automatic cleanup for expired advertisements/requests**
8. **Use event-driven discovery** for real-time notifications
9. **Verify signatures** on advertisements and requests to prevent poisoning

### Visual Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Lotus P2P DHT Architecture                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Network Layer:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Node A  â”‚â—„â”€â”€â”€â–ºâ”‚  Node B  â”‚â—„â”€â”€â”€â–ºâ”‚  Node C  â”‚
  â”‚ (Server) â”‚     â”‚ (Server) â”‚     â”‚ (Client) â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²                 â–²                 â–²
       â”‚                 â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              Kademlia DHT Network
              (Resource Announcements)

Session Coordination:
  Session Creator â”€â”€â–º Announce to DHT â”€â”€â–º Store on k nodes
                  â”€â”€â–º Broadcast to P2P â”€â”€â–º Direct messages

  Participants â”€â”€â”€â”€â”€â–º Discover from DHT â”€â”€â–º Query network
               â”€â”€â”€â”€â”€â–º Join session â”€â”€â”€â”€â”€â”€â”€â”€â–º Direct messages
               â”€â”€â”€â”€â”€â–º Exchange nonces â”€â”€â”€â”€â”€â–º Direct P2P
               â”€â”€â”€â”€â”€â–º Exchange sigs â”€â”€â”€â”€â”€â”€â”€â–º Direct P2P
               â”€â”€â”€â”€â”€â–º Finalize â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Complete!

Data Flow:
  [Session] â†’ announceResource() â†’ Local Cache â†’ DHT Network
  [Query]   â†’ discoverResource() â†’ Local Cache â†’ DHT Query â†’ Result
  [Message] â†’ sendTo() â†’ libp2p stream â†’ Peer
```

---

## Related Documentation

- [P2P README](../lib/p2p/README.md) - P2P infrastructure overview
- [MuSig2 P2P Coordination](MUSIG2_P2P_COORDINATION.md) - MuSig2-specific patterns
- [libp2p Documentation](https://docs.libp2p.io/) - Official libp2p docs
- [Kademlia Paper](https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf) - Original algorithm

---

**Built with libp2p for the Lotus Ecosystem** ðŸŒ¸
